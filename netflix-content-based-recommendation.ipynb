{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Netflix Movie and TV Show Recommendation","metadata":{}},{"cell_type":"markdown","source":"In this notebook, we are going to build a recommender system based on [Netflix](https://www.kaggle.com/datasets/shivamb/netflix-shows) dataset. There are several types of recommender systems, one of which is Content-Based Filtering. That's what we focus on in this particular notebook since we are not dealing with any user data such as user's rating and review. The idea is to get the features of each item (content) and give the user a recommendation based on the similarity between them\n\n**Let's jump right into the code**\n\n\n\n\n![](https://www.researchgate.net/profile/Lionel-Ngoupeyou-Tondji/publication/323726564/figure/fig5/AS:631605009846299@1527597777415/Content-based-filtering-vs-Collaborative-filtering-Source.png)","metadata":{}},{"cell_type":"markdown","source":"### Importing Libraries","metadata":{}},{"cell_type":"code","source":"import string\nimport numpy as np\nimport pandas as pd\nimport sklearn\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:17:20.481372Z","iopub.execute_input":"2022-06-03T03:17:20.481900Z","iopub.status.idle":"2022-06-03T03:17:21.025643Z","shell.execute_reply.started":"2022-06-03T03:17:20.481855Z","shell.execute_reply":"2022-06-03T03:17:21.024132Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Loading and Understanding the Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/netflix-shows/netflix_titles.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:17:21.027518Z","iopub.execute_input":"2022-06-03T03:17:21.027950Z","iopub.status.idle":"2022-06-03T03:17:21.201514Z","shell.execute_reply.started":"2022-06-03T03:17:21.027903Z","shell.execute_reply":"2022-06-03T03:17:21.200152Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:17:21.203123Z","iopub.execute_input":"2022-06-03T03:17:21.203637Z","iopub.status.idle":"2022-06-03T03:17:21.303749Z","shell.execute_reply.started":"2022-06-03T03:17:21.203585Z","shell.execute_reply":"2022-06-03T03:17:21.302782Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:17:21.306529Z","iopub.execute_input":"2022-06-03T03:17:21.307062Z","iopub.status.idle":"2022-06-03T03:17:21.336336Z","shell.execute_reply.started":"2022-06-03T03:17:21.307013Z","shell.execute_reply":"2022-06-03T03:17:21.335256Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame({'Total missing values':df.isna().sum(),\n              'Percentage':(df.isna().sum()/len(df))*100})","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:17:21.337769Z","iopub.execute_input":"2022-06-03T03:17:21.339200Z","iopub.status.idle":"2022-06-03T03:17:21.386891Z","shell.execute_reply.started":"2022-06-03T03:17:21.339151Z","shell.execute_reply":"2022-06-03T03:17:21.385825Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Build the Recommender System","metadata":{}},{"cell_type":"markdown","source":"We won't use all the columns or features for this notebook. So then, the recommendation that we give to the users will only consider the information contained in the following columns:\n- Type\n- Director\n- Rating\n- Listed_in\n- Description","metadata":{}},{"cell_type":"code","source":"new_df = df[['title', 'type', 'director', 'cast', 'rating', 'listed_in', 'description']]\nnew_df.set_index('title', inplace=True)\nnew_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:17:21.388157Z","iopub.execute_input":"2022-06-03T03:17:21.389370Z","iopub.status.idle":"2022-06-03T03:17:21.408463Z","shell.execute_reply.started":"2022-06-03T03:17:21.389332Z","shell.execute_reply":"2022-06-03T03:17:21.407582Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"If you take a look at the missing values in this dataset, you will realize that the director column has 2634 NaN values which correspond with almost 30 percents of total data in that column. So, we can't just drop the NaN values because we will lose lots of movies to be given, instead we just fill the NaN values with empty string","metadata":{}},{"cell_type":"code","source":"new_df.fillna('', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:17:21.409612Z","iopub.execute_input":"2022-06-03T03:17:21.410358Z","iopub.status.idle":"2022-06-03T03:17:21.425870Z","shell.execute_reply.started":"2022-06-03T03:17:21.410321Z","shell.execute_reply":"2022-06-03T03:17:21.424381Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# For director, cast, and listed_in\n# Because there is more than 1 people and categories\n# We don't want if people share the same first or last name consider the same person\n# or the word that appear in many categories (TV, etc) consider the same category\ndef separate(texts):\n    t = []\n    for text in texts.split(','):\n        t.append(text.replace(' ', '').lower())\n    return ' '.join(t)\n\ndef remove_space(texts):\n    return texts.replace(' ', '').lower()\n\ndef remove_punc(texts):\n    return texts.translate(str.maketrans('','',string.punctuation)).lower()","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:17:21.428554Z","iopub.execute_input":"2022-06-03T03:17:21.429046Z","iopub.status.idle":"2022-06-03T03:17:21.438870Z","shell.execute_reply.started":"2022-06-03T03:17:21.429005Z","shell.execute_reply":"2022-06-03T03:17:21.436819Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"new_df['type'] = new_df['type'].apply(remove_space)\nnew_df['director'] = new_df['director'].apply(separate)\nnew_df['cast'] = new_df['cast'].apply(separate)\nnew_df['rating'] = new_df['rating'].apply(remove_space)\nnew_df['listed_in'] = new_df['listed_in'].apply(separate)\nnew_df['description'] = new_df['description'].apply(remove_punc)\n\nnew_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:17:21.556301Z","iopub.execute_input":"2022-06-03T03:17:21.557383Z","iopub.status.idle":"2022-06-03T03:17:21.723776Z","shell.execute_reply.started":"2022-06-03T03:17:21.557325Z","shell.execute_reply":"2022-06-03T03:17:21.722946Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"new_df['bag_of_words'] = ''\n\n# Combine all the words into 1 column\nfor i, row in enumerate(new_df.iterrows()):\n    string = ''\n    for col in new_df.columns:\n        if row[1][col] == '':\n            continue\n        else:\n            string += row[1][col] + ' '\n            new_df['bag_of_words'][i] = string.strip()\n\nnew_df.drop(new_df.columns[:-1], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:17:21.725266Z","iopub.execute_input":"2022-06-03T03:17:21.725759Z","iopub.status.idle":"2022-06-03T03:17:30.518451Z","shell.execute_reply.started":"2022-06-03T03:17:21.725728Z","shell.execute_reply":"2022-06-03T03:17:30.517452Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"new_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:17:30.520199Z","iopub.execute_input":"2022-06-03T03:17:30.520575Z","iopub.status.idle":"2022-06-03T03:17:30.530531Z","shell.execute_reply.started":"2022-06-03T03:17:30.520542Z","shell.execute_reply":"2022-06-03T03:17:30.529536Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:17:30.531973Z","iopub.execute_input":"2022-06-03T03:17:30.532553Z","iopub.status.idle":"2022-06-03T03:17:30.643738Z","shell.execute_reply.started":"2022-06-03T03:17:30.532519Z","shell.execute_reply":"2022-06-03T03:17:30.642809Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"**TF-IDF** stands for Term Frequency â€” Inverse Document Frequency. It tells the importance of a word. In a nutshell, The word that appear more frequently in the corpus, it will be considered less importance, hence the tfidf score will be lower. It goes the opposite way with less frequent word|","metadata":{}},{"cell_type":"code","source":"tfid = TfidfVectorizer()\ntfid_matrix = tfid.fit_transform(new_df['bag_of_words'])\n\n#tfid_matrix.vocabulary_","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:17:30.645898Z","iopub.execute_input":"2022-06-03T03:17:30.646739Z","iopub.status.idle":"2022-06-03T03:17:31.721486Z","shell.execute_reply.started":"2022-06-03T03:17:30.646672Z","shell.execute_reply":"2022-06-03T03:17:31.720099Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"cosine_sim = cosine_similarity(tfid_matrix, tfid_matrix)\ncosine_sim","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:17:31.722994Z","iopub.execute_input":"2022-06-03T03:17:31.723404Z","iopub.status.idle":"2022-06-03T03:17:36.073263Z","shell.execute_reply.started":"2022-06-03T03:17:31.723373Z","shell.execute_reply":"2022-06-03T03:17:36.071612Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Later on we will combine with similarity as a column\nfinal_df = df[['title', 'type']]","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:17:36.076052Z","iopub.execute_input":"2022-06-03T03:17:36.076769Z","iopub.status.idle":"2022-06-03T03:17:36.085240Z","shell.execute_reply.started":"2022-06-03T03:17:36.076684Z","shell.execute_reply":"2022-06-03T03:17:36.083370Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def recommendation(title, total_result=5, threshold=0.5):\n    # Get the index\n    idx = final_df[final_df['title'] == title].index[0]\n    # Create a new column for similarity, the value is different for each title you input\n    final_df['similarity'] = cosine_sim[idx]\n    sort_final_df = final_df.sort_values(by='similarity', ascending=False)[1:total_result+1]\n    \n    # You can set a threshold if you want to norrow the result down \n    #sort_final_df = sort_final_df[sort_final_df['similarity'] > threshold]\n    \n    # Is the title a movie or tv show?\n    movies = sort_final_df['title'][sort_final_df['type'] == 'Movie']\n    tv_shows = sort_final_df['title'][sort_final_df['type'] == 'TV Show']\n    \n    if len(movies) != 0:\n        print('Similar Movie(s) list:')\n        for i, movie in enumerate(movies):\n            print('{}. {}'.format(i+1, movie))\n        print()\n    else:\n        print('Similar Movie(s) list:')\n        print('-\\n')\n        \n    if len(tv_shows) != 0:\n        print('Similar TV_show(s) list:')\n        for i, tv_show in enumerate(tv_shows):\n            print('{}. {}'.format(i+1, tv_show))\n    else:\n        print('Similar TV_show(s) list:')\n        print('-')","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:17:36.088183Z","iopub.execute_input":"2022-06-03T03:17:36.088833Z","iopub.status.idle":"2022-06-03T03:17:36.103547Z","shell.execute_reply.started":"2022-06-03T03:17:36.088762Z","shell.execute_reply":"2022-06-03T03:17:36.101842Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### Recommendation Example","metadata":{}},{"cell_type":"code","source":"recommendation('Breaking Bad')","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:17:36.106066Z","iopub.execute_input":"2022-06-03T03:17:36.106676Z","iopub.status.idle":"2022-06-03T03:17:36.131492Z","shell.execute_reply.started":"2022-06-03T03:17:36.106617Z","shell.execute_reply":"2022-06-03T03:17:36.129985Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"recommendation('Narcos')","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:17:36.135086Z","iopub.execute_input":"2022-06-03T03:17:36.135496Z","iopub.status.idle":"2022-06-03T03:17:36.148028Z","shell.execute_reply.started":"2022-06-03T03:17:36.135465Z","shell.execute_reply":"2022-06-03T03:17:36.146647Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"recommendation('Chappie')","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:17:36.151714Z","iopub.execute_input":"2022-06-03T03:17:36.152301Z","iopub.status.idle":"2022-06-03T03:17:36.168140Z","shell.execute_reply.started":"2022-06-03T03:17:36.152251Z","shell.execute_reply":"2022-06-03T03:17:36.166320Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"recommendation('Stranger Things')","metadata":{"execution":{"iopub.status.busy":"2022-06-03T03:17:36.169932Z","iopub.execute_input":"2022-06-03T03:17:36.170382Z","iopub.status.idle":"2022-06-03T03:17:36.187936Z","shell.execute_reply.started":"2022-06-03T03:17:36.170338Z","shell.execute_reply":"2022-06-03T03:17:36.186827Z"},"trusted":true},"execution_count":22,"outputs":[]}]}